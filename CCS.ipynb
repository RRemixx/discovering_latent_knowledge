{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement CCS from scratch.\n",
    "This will deliberately be a simple (but less efficient) implementation to make everything as clear as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asuka/anaconda3/envs/llm/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset parquet (/home/asuka/.cache/huggingface/datasets/parquet/amazon_polarity-d48d00b6869479db/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.50it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xxlarge were not used when initializing DebertaV2ForMaskedLM: ['deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-v2-xxlarge and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Let's just try IMDB for simplicity\n",
    "data = load_dataset(\"amazon_polarity\")[\"test\"]\n",
    "\n",
    "# Here are a few different model options you can play around with:\n",
    "model_name = \"deberta\"\n",
    "# model_name = \"gpt-j\"\n",
    "# model_name = \"t5\"\n",
    "\n",
    "# if you want to cache the model weights somewhere, you can specify that here\n",
    "cache_dir = None\n",
    "\n",
    "if model_name == \"deberta\":\n",
    "    model_type = \"encoder\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v2-xxlarge\", cache_dir=cache_dir)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\"microsoft/deberta-v2-xxlarge\", cache_dir=cache_dir)\n",
    "    model.cuda()\n",
    "elif model_name == \"gpt-j\":\n",
    "    model_type = \"decoder\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\", cache_dir=cache_dir)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", cache_dir=cache_dir)\n",
    "    model.cuda()\n",
    "elif model_name == \"t5\":\n",
    "    model_type = \"encoder_decoder\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-11b\", cache_dir=cache_dir)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-11b\", cache_dir=cache_dir)\n",
    "    model.parallelize()  # T5 is big enough that we may need to run it on multiple GPUs\n",
    "else:\n",
    "    print(\"Not implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's write code for extracting hidden states given a model and text. \n",
    "How we do this exactly will depend on the type of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder_hidden_states(model, tokenizer, input_text, layer=-1):\n",
    "    \"\"\"\n",
    "    Given an encoder model and some text, gets the encoder hidden states (in a given layer, by default the last) \n",
    "    on that input text (where the full text is given to the encoder).\n",
    "\n",
    "    Returns a numpy array of shape (hidden_dim,)\n",
    "    \"\"\"\n",
    "    # tokenize\n",
    "    encoder_text_ids = tokenizer(input_text, truncation=True, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(encoder_text_ids, output_hidden_states=True)\n",
    "\n",
    "    # get the appropriate hidden states\n",
    "    hs_tuple = output[\"hidden_states\"]\n",
    "    \n",
    "    hs = hs_tuple[layer][0, -1].detach().cpu().numpy()\n",
    "\n",
    "    return hs\n",
    "\n",
    "def get_encoder_decoder_hidden_states(model, tokenizer, input_text, layer=-1):\n",
    "    \"\"\"\n",
    "    Given an encoder-decoder model and some text, gets the encoder hidden states (in a given layer, by default the last) \n",
    "    on that input text (where the full text is given to the encoder).\n",
    "\n",
    "    Returns a numpy array of shape (hidden_dim,)\n",
    "    \"\"\"\n",
    "    # tokenize\n",
    "    encoder_text_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    decoder_text_ids = tokenizer(\"\", return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(encoder_text_ids, decoder_input_ids=decoder_text_ids, output_hidden_states=True)\n",
    "\n",
    "    # get the appropriate hidden states\n",
    "    hs_tuple = output[\"encoder_hidden_states\"]\n",
    "    hs = hs_tuple[layer][0, -1].detach().cpu().numpy()\n",
    "\n",
    "    return hs\n",
    "\n",
    "def get_decoder_hidden_states(model, tokenizer, input_text, layer=-1):\n",
    "    \"\"\"\n",
    "    Given a decoder model and some text, gets the hidden states (in a given layer, by default the last) on that input text\n",
    "\n",
    "    Returns a numpy array of shape (hidden_dim,)\n",
    "    \"\"\"\n",
    "    # tokenize (adding the EOS token this time)\n",
    "    input_ids = tokenizer(input_text + tokenizer.eos_token, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, output_hidden_states=True)\n",
    "\n",
    "    # get the last layer, last token hidden states\n",
    "    hs_tuple = output[\"hidden_states\"]\n",
    "    hs = hs_tuple[layer][0, -1].detach().cpu().numpy()\n",
    "\n",
    "    return hs\n",
    "\n",
    "def get_hidden_states(model, tokenizer, input_text, layer=-1, model_type=\"encoder\"):\n",
    "    fn = {\"encoder\": get_encoder_hidden_states, \"encoder_decoder\": get_encoder_decoder_hidden_states,\n",
    "          \"decoder\": get_decoder_hidden_states}[model_type]\n",
    "\n",
    "    return fn(model, tokenizer, input_text, layer=layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's write code for formatting data and for getting all the hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_imdb(text, label):\n",
    "    \"\"\"\n",
    "    Given an imdb example (\"text\") and corresponding label (0 for negative, or 1 for positive), \n",
    "    returns a zero-shot prompt for that example (which includes that label as the answer).\n",
    "    \n",
    "    (This is just one example of a simple, manually created prompt.)\n",
    "    \"\"\"\n",
    "    return \"The following movie review expresses a \" + [\"negative\", \"positive\"][label] + \" sentiment:\\n\" + text\n",
    "\n",
    "\n",
    "def get_hidden_states_many_examples(model, tokenizer, data, model_type, n=100):\n",
    "    \"\"\"\n",
    "    Given an encoder-decoder model, a list of data, computes the contrast hidden states on n random examples.\n",
    "    Returns numpy arrays of shape (n, hidden_dim) for each candidate label, along with a boolean numpy array of shape (n,)\n",
    "    with the ground truth labels\n",
    "    \n",
    "    This is deliberately simple so that it's easy to understand, rather than being optimized for efficiency\n",
    "    \"\"\"\n",
    "    # setup\n",
    "    model.eval()\n",
    "    all_neg_hs, all_pos_hs, all_gt_labels = [], [], []\n",
    "\n",
    "    # loop\n",
    "    for _ in tqdm(range(n)):\n",
    "        # for simplicity, sample a random example until we find one that's a reasonable length\n",
    "        # (most examples should be a reasonable length, so this is just to make sure)\n",
    "        while True:\n",
    "            idx = np.random.randint(len(data))\n",
    "            text, true_label = data[idx][\"content\"], data[idx][\"label\"]\n",
    "            # the actual formatted input will be longer, so include a bit of a marign\n",
    "            if len(tokenizer(text)) < 400:  \n",
    "                break\n",
    "                \n",
    "        # get hidden states\n",
    "        neg_hs = get_hidden_states(model, tokenizer, format_imdb(text, 0), model_type=model_type)\n",
    "        pos_hs = get_hidden_states(model, tokenizer, format_imdb(text, 1), model_type=model_type)\n",
    "\n",
    "        # collect\n",
    "        all_neg_hs.append(neg_hs)\n",
    "        all_pos_hs.append(pos_hs)\n",
    "        all_gt_labels.append(true_label)\n",
    "\n",
    "    all_neg_hs = np.stack(all_neg_hs)\n",
    "    all_pos_hs = np.stack(all_pos_hs)\n",
    "    all_gt_labels = np.stack(all_gt_labels)\n",
    "\n",
    "    return all_neg_hs, all_pos_hs, all_gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "neg_hs, pos_hs, y = get_hidden_states_many_examples(model, tokenizer, data, model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's verify that the model's representations are good\n",
    "\n",
    "Before trying CCS, let's make sure there exists a direction that classifies examples as true vs false with high accuracy; if logistic regression accuracy is bad, there's no hope of CCS doing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# let's create a simple 50/50 train split (the data is already randomized)\n",
    "n = len(y)\n",
    "neg_hs_train, neg_hs_test = neg_hs[:n//2], neg_hs[n//2:]\n",
    "pos_hs_train, pos_hs_test = pos_hs[:n//2], pos_hs[n//2:]\n",
    "y_train, y_test = y[:n//2], y[n//2:]\n",
    "\n",
    "# for simplicity we can just take the difference between positive and negative hidden states\n",
    "# (concatenating also works fine)\n",
    "x_train = neg_hs_train - pos_hs_train\n",
    "x_test = neg_hs_test - pos_hs_test\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "lr.fit(x_train, y_train)\n",
    "print(\"Logistic regression accuracy: {}\".format(lr.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try CCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MLPProbe(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d, 100)\n",
    "        self.linear2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.linear1(x))\n",
    "        o = self.linear2(h)\n",
    "        return torch.sigmoid(o)\n",
    "\n",
    "class CCS(object):\n",
    "    def __init__(self, x0, x1, nepochs=1000, ntries=10, lr=1e-3, batch_size=-1, \n",
    "                 verbose=False, device=\"cuda\", linear=True, weight_decay=0.01, var_normalize=False):\n",
    "        # data\n",
    "        self.var_normalize = var_normalize\n",
    "        self.x0 = self.normalize(x0)\n",
    "        self.x1 = self.normalize(x1)\n",
    "        self.d = self.x0.shape[-1]\n",
    "\n",
    "        # training\n",
    "        self.nepochs = nepochs\n",
    "        self.ntries = ntries\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # probe\n",
    "        self.linear = linear\n",
    "        self.initialize_probe()\n",
    "        self.best_probe = copy.deepcopy(self.probe)\n",
    "\n",
    "        \n",
    "    def initialize_probe(self):\n",
    "        if self.linear:\n",
    "            self.probe = nn.Sequential(nn.Linear(self.d, 1), nn.Sigmoid())\n",
    "        else:\n",
    "            self.probe = MLPProbe(self.d)\n",
    "        self.probe.to(self.device)    \n",
    "\n",
    "\n",
    "    def normalize(self, x):\n",
    "        \"\"\"\n",
    "        Mean-normalizes the data x (of shape (n, d))\n",
    "        If self.var_normalize, also divides by the standard deviation\n",
    "        \"\"\"\n",
    "        normalized_x = x - x.mean(axis=0, keepdims=True)\n",
    "        if self.var_normalize:\n",
    "            normalized_x /= normalized_x.std(axis=0, keepdims=True)\n",
    "\n",
    "        return normalized_x\n",
    "\n",
    "        \n",
    "    def get_tensor_data(self):\n",
    "        \"\"\"\n",
    "        Returns x0, x1 as appropriate tensors (rather than np arrays)\n",
    "        \"\"\"\n",
    "        x0 = torch.tensor(self.x0, dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        x1 = torch.tensor(self.x1, dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        return x0, x1\n",
    "    \n",
    "\n",
    "    def get_loss(self, p0, p1):\n",
    "        \"\"\"\n",
    "        Returns the CCS loss for two probabilities each of shape (n,1) or (n,)\n",
    "        \"\"\"\n",
    "        informative_loss = (torch.min(p0, p1)**2).mean(0)\n",
    "        consistent_loss = ((p0 - (1-p1))**2).mean(0)\n",
    "        return informative_loss + consistent_loss\n",
    "\n",
    "\n",
    "    def get_acc(self, x0_test, x1_test, y_test):\n",
    "        \"\"\"\n",
    "        Computes accuracy for the current parameters on the given test inputs\n",
    "        \"\"\"\n",
    "        x0 = torch.tensor(self.normalize(x0_test), dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        x1 = torch.tensor(self.normalize(x1_test), dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            p0, p1 = self.best_probe(x0), self.best_probe(x1)\n",
    "        avg_confidence = 0.5*(p0 + (1-p1))\n",
    "        predictions = (avg_confidence.detach().cpu().numpy() < 0.5).astype(int)[:, 0]\n",
    "        acc = (predictions == y_test).mean()\n",
    "        acc = max(acc, 1 - acc)\n",
    "\n",
    "        return acc\n",
    "    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Does a single training run of nepochs epochs\n",
    "        \"\"\"\n",
    "        x0, x1 = self.get_tensor_data()\n",
    "        permutation = torch.randperm(len(x0))\n",
    "        x0, x1 = x0[permutation], x1[permutation]\n",
    "        \n",
    "        # set up optimizer\n",
    "        optimizer = torch.optim.AdamW(self.probe.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        \n",
    "        batch_size = len(x0) if self.batch_size == -1 else self.batch_size\n",
    "        nbatches = len(x0) // batch_size\n",
    "\n",
    "        # Start training (full batch)\n",
    "        for epoch in range(self.nepochs):\n",
    "            for j in range(nbatches):\n",
    "                x0_batch = x0[j*batch_size:(j+1)*batch_size]\n",
    "                x1_batch = x1[j*batch_size:(j+1)*batch_size]\n",
    "            \n",
    "                # probe\n",
    "                p0, p1 = self.probe(x0_batch), self.probe(x1_batch)\n",
    "\n",
    "                # get the corresponding loss\n",
    "                loss = self.get_loss(p0, p1)\n",
    "\n",
    "                # update the parameters\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return loss.detach().cpu().item()\n",
    "    \n",
    "    def repeated_train(self):\n",
    "        best_loss = np.inf\n",
    "        for train_num in range(self.ntries):\n",
    "            self.initialize_probe()\n",
    "            loss = self.train()\n",
    "            if loss < best_loss:\n",
    "                self.best_probe = copy.deepcopy(self.probe)\n",
    "                best_loss = loss\n",
    "\n",
    "        return best_loss\n",
    "    \n",
    "    def supervised_train(self, labels, batch_size=-1, verbose=False, num_data_points=None, nepochs=0):\n",
    "        \"\"\"\n",
    "        Trains the probe using the provided labels (0/1)\n",
    "        Args:\n",
    "            num_data_points: Number of data points to use for training. If None, use all data points.\n",
    "        Returns both final loss and loss history\n",
    "        \"\"\"\n",
    "        x0, x1 = self.get_tensor_data()\n",
    "        x = torch.cat([x0, x1], dim=0)\n",
    "        y = torch.tensor(np.concatenate([labels, labels]), dtype=torch.float, requires_grad=False, device=self.device).reshape(-1, 1)\n",
    "        \n",
    "        if num_data_points is not None and num_data_points < len(x):\n",
    "            # Randomly select num_data_points data points\n",
    "            indices = torch.randperm(len(x))[:num_data_points]\n",
    "            x = x[indices]\n",
    "            y = y[indices]\n",
    "        \n",
    "        # Check x and y values\n",
    "        # Print a few examples to check data\n",
    "        print(\"First 5 x values:\", x[:5])\n",
    "        print(\"First 5 y values:\", y[:5])\n",
    "        print(\"Shape of x:\", x.shape)\n",
    "        print(\"Shape of y:\", y.shape)\n",
    "        print(\"Unique y values:\", torch.unique(y))\n",
    "        \n",
    "        # check the distributio of y\n",
    "        print(\"Distribution of y values:\", torch.bincount(y.flatten().long()))\n",
    "        \n",
    "        # set up optimizer\n",
    "        optimizer = torch.optim.AdamW(self.probe.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        \n",
    "        if batch_size == -1:\n",
    "            batch_size = len(x)\n",
    "        nbatches = len(x) // batch_size\n",
    "        print(len(x), batch_size, nbatches)\n",
    "\n",
    "        # Track loss history\n",
    "        loss_history = []\n",
    "\n",
    "        # Start training\n",
    "        for epoch in tqdm(range(nepochs)):\n",
    "            epoch_loss = 0.0\n",
    "            # Randomly shuffle the data at each epoch\n",
    "            perm = torch.randperm(len(x))\n",
    "            x_shuffled = x[perm]\n",
    "            y_shuffled = y[perm]\n",
    "            \n",
    "            for j in range(nbatches):\n",
    "                x_batch = x_shuffled[j*batch_size:(j+1)*batch_size]\n",
    "                y_batch = y_shuffled[j*batch_size:(j+1)*batch_size]\n",
    "\n",
    "                # probe\n",
    "                p = self.probe(x_batch)\n",
    "                \n",
    "                # check some of the model outputs in a batch\n",
    "                # print(\"Model outputs (probabilities):\", p[:5])\n",
    "                # print(\"Corresponding labels:\", y_batch[:5])\n",
    "\n",
    "                # get the corresponding loss\n",
    "                loss = F.binary_cross_entropy(p, y_batch)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # update the parameters\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Record average loss for this epoch\n",
    "            loss_history.append(epoch_loss / nbatches)\n",
    "            # Print loss for this epoch\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{self.nepochs}, Loss: {epoch_loss / nbatches:.4f}\")\n",
    "\n",
    "        # visualize the loss_history\n",
    "        # if verbose:\n",
    "        plt.plot(loss_history)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Loss History\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Train CCS without any labels\n",
    "ccs = CCS(neg_hs_train, pos_hs_train)\n",
    "ccs.repeated_train()\n",
    "\n",
    "# Evaluate\n",
    "ccs_acc = ccs.get_acc(neg_hs_test, pos_hs_test, y_test)\n",
    "print(\"CCS accuracy: {}\".format(ccs_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 x values: tensor([[ 0.0786,  0.1039,  0.2052,  ..., -0.2165,  0.1251, -0.2639],\n",
      "        [-0.0629, -0.1365, -0.2764,  ...,  0.2124, -0.0936,  0.0724],\n",
      "        [-0.1771,  0.1240, -0.3412,  ..., -0.3369,  0.0295, -0.0730],\n",
      "        [-0.1743, -0.6338,  0.2383,  ...,  0.0255,  0.1781, -0.3138],\n",
      "        [ 0.1976,  0.2610,  0.1803,  ..., -0.0456, -0.1420, -0.0718]],\n",
      "       device='cuda:0')\n",
      "First 5 y values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]], device='cuda:0')\n",
      "Shape of x: torch.Size([100, 1536])\n",
      "Shape of y: torch.Size([100, 1])\n",
      "Unique y values: tensor([0., 1.], device='cuda:0')\n",
      "Distribution of y values: tensor([54, 46], device='cuda:0')\n",
      "100 100 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 874.04it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS supervised accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Train CCS with labels\n",
    "ccs_supervised = CCS(neg_hs_train, pos_hs_train)\n",
    "ccs_supervised.supervised_train(y_train, batch_size=-1, verbose=False, nepochs=1000)\n",
    "# ccs_supervised.repeated_train()\n",
    "\n",
    "# Evaluate\n",
    "ccs_supervised_acc = ccs_supervised.get_acc(neg_hs_test, pos_hs_test, y_test)\n",
    "print(\"CCS supervised accuracy: {}\".format(ccs_supervised_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
